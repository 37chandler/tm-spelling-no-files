{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the slides for our class on spelling correction. \n",
    "\n",
    "---\n",
    "\n",
    "### First Task\n",
    "The file “wsj_with_errors.txt” has a bunch of text in it. \n",
    "* Ingest this file.\n",
    "* Remove punctuation and numbers.\n",
    "* Cast to lowercase.\n",
    "* Take every word that’s not in the NLTK word corpus and write it to a file. (Moving NLTK words to lowercase is a good idea.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus \n",
    "\n",
    "words = nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wsj_with_errors.txt\") as infile : \n",
    "    for idx, line in enumerate(infile) : \n",
    "        print(line)\n",
    "        if idx == 4 :\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Second Task\n",
    "\n",
    "* The file “big.txt” has about 1M words, mostly from Gutenberg. Now use words in this file (instead of the NLTK word corpus). \n",
    "* So, repeat the previous exercise, but this time use the 1M corpus as your comparison set. \n",
    "    * Note that this file requires similar cleaning. It has numbers and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"big.txt\") as infile : \n",
    "    for idx, line in enumerate(infile) : \n",
    "        print(line)\n",
    "        if idx == 4 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Write a function that takes a word as input and returns every deletion. Sort them for the assertion statements to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletions(word) :\n",
    "    \n",
    "    deletions = []\n",
    "    \n",
    "    # Fill up this list with all strings that are \"word\" with a \n",
    "    # single character removed. You should have a list of length\n",
    "    # len(word)\n",
    "    \n",
    "    return(sorted(deletions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(deletions(\"help\")==['elp', 'hel', 'hep', 'hlp'])\n",
    "assert(deletions(\"me\")==['e','m'])\n",
    "assert(deletions(\"textmining\")==['extmining','tetmining','texmining','textining','textmiing',\n",
    "                                 'textminig','textminin','textminng','textmning','txtmining'])\n",
    "\n",
    "print(\"All assertion tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
